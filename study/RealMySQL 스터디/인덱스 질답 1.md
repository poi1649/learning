
- DB 암호화 vs 응용 프로그램 암호화
    
    - 응용 프로그램에서 암호화는 db 의 쿼리로 누릴 수 있는 장점이 없어진다.
        - 정렬, 범위 검색 등
    - DB 암호화는 db에서 평문으로 확인할 수 있다. 비즈니스 구조상 암호화가 필요하다면 위의 이점을 포기해서라도 암호화해서 사용하는게 좋다.
- 테이블 스페이스 복사 과정에 대해 설명해주세요
    
    - 버퍼 풀에 있는 내용 플러시 → 데이터를 다른 서버로 이동 → 잠금 해제
    - 암호화 과정이 있다면 저장된 테이블 스페이스 키를 복호화해서 새로 발급받은 임시 마스터키로 다시 암호화하고 그 키와 데이터를 서버로 전송 한다.
- 테이블 스페이스 이동은 덤프보다 성능이 좋다
    
- 바이너리 로그는? 릴레이 로그는?
    
    - 바이너리 로그: DB에서 발생하는 모든 동작에 대해서 이력을 남기는 로그
        - 형태는 STATEMENT일 수도 있고, ROW일 수도 있다.
    - 릴레이 로그: 바이너리 로그를 복제해서 사용하고 있는 데이터에 발생한 로그
        - 소스에서 발생한 로그를 복제한 곳에 전달해 주는 로그
- RAID 컨트롤러에 대해 아시나요?
    
- 랜덤 IO와 순차 IO 에서 무조건적으로 순차 IO의 성능이 좋다. 그래서 랜덤 IO를 합쳐서 순차 IO로 최적화 해주는 작업을 디스크 내부에서 한다. 이 기능을 하는 부분을 RAID 컨트롤러라고 한다.
    
- 인덱스 RANGE SCAN이 주로 랜덤 IO 를 사용하는 이유? pk가 클러스터링 되어 있는 거랑 별개임
    
    - 인덱스에 매핑되는 실제 데이터 파일이 저장되는 위치는 불연속적일수 있다.
- 리두로그와 언두로그의 암호화 과정에 대해 설명해주세요
    
    - 각각의 파일키를 만든다. 해당이 테이블스페이스키와 같은 역할을 한다.
- 언두로그와 리두로그를 암호화 하다가 비활성화하게 되면 기존 암호화된 값들은 어떻게 될까요?
    
    - 여전히 암호화 되어 있습니다.
- 4일
    
    - 인덱스에서 사용하는 자료구조
        - B-tree
            - 노드의 키를 컬럼으로 가지고 있다.
            - 삽입 삭제에 큰 비용이 소요가된다.
            - 읽기 연산이 메인이 되기 때문에 해당 연산에 이점을 가진 비트리를 많이쓴다.
        - Hash-Map
            - 해시 값을 키로 가지고, 이를 1:1 매핑
            - 해싱을 한 뒤에 검색 속도가 앞선다.
            - 키가 랜덤한 해시값이다보니 범위검색 같은 것이 안된다.
    - DBMS의 인덱스 정렬 기준은?
        - 해당 칼럼의 키 값
    - 인덱스란?
        - 현실 세계에선 책 앞의 목차를 말한다. DB에선 데이터를 빠르게 찾아갈 수 있도록 하는 지표이다.
    - 인덱스를 왜 사용하나요?
        - 어느 위치에 어떤 데이터가 있는지에 대한 정보를 관리함으로써 데이터를 빠르게 찾을 수 있도록 한다.
    - 비트리의 깊이에 따라서 연산속도가 차이가 난다. 그럼 깊이를 관리하는 우리의 방법이 있을까요?
        - 키값의 크기를 통해 관리하게 된다. 노드의 크기가 클수록 한 페이지 당 노드 개수가 줄어들어서 결국 페이지가 많아져서 깊이가 깊어진다.
        - 용어정리 → 페이지가 곧 노드이다. 해당 노드는 곧 페이지이다.
        - 페이지에서는 노드의 정보 (키 값, 주소 만 관리하기 때문에 여러개 들어갈 수 있다.)
    - 인덱스 키 추가 과정을 설명해주세요
        - 페이지에서 인덱스를 찾아서 노드가 들어갈의 위치를 찾아서 해당 위치 + 리프노드에 삽입
        - 삭제는 마킹을 해놓는다. 인덱스 페이지 전체가 변경되기 때문에 트리 구조를 유지하기위해 시간이 오래 걸린다. (체인지 버퍼에 의해 지연처리)
    - 체인지 버퍼를 활용해 지연처리되는 과정 설명해주세요
        - 리프노드의 페이지가 버퍼풀에 올라와있다면 바로 페이지에 삽입, 아니라면 체인지 버퍼에 잠시동안 캐싱 유저가 데이터를 찾으면 체인지 버퍼에서 가져오고 write할 때 리프노드에 추가. 유니크나 primary key 같은 경우는 직접 삽입
    - 키 값이 크면 성능 저하가 생길까요?
        - B-tree의 깊이와 관계 있다. 키 값의 크기가 작은 페이지는 한 페이지에 많이 들어갈 수 있다. 이때 들어갈 수 있는 값이 500개라고 하고, 키 값의 크기가 큰 페이지에는 200개가 들어간다고 가정하자. 이때 단순히 300개의 차이로 끝나는 게 아니라 페이지가 늘어날수록 계속해서 곱해지기 때문에 문제가 생긴다.
    - 카디널리티와 관련하여?
        - 특정 컬럼에 대해 검색했을 때, a 컬럼에 대해 조회했을 때는 10개의 결과가 나오고 b 컬럼에 대해 조회했을 때는 1개의 결과만 나온다고 가정. 이때는 b 컬럼에 대해 조회하는 게 더 효율적이다. a 컬럼에 대해서는 불필요한 9개의 row도 함께 조회하기 때문